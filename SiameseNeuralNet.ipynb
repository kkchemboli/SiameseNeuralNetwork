{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731911bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m29 packages\u001b[0m \u001b[2min 207ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/5.13 MiB            \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/5.13 MiB            \u001b[1A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/5.13 MiB            \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 16.00 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 32.00 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 48.00 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 62.40 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 62.40 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 78.40 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 94.40 KiB/5.13 MiB          \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 110.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 126.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 126.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 142.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 142.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 158.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 64.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 158.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 64.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 174.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 80.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 174.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 160.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 206.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 256.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 302.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 384.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 398.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 464.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 526.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 576.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 638.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 672.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 830.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 800.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 974.40 KiB/5.13 MiB         \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 880.00 KiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.11 MiB/5.13 MiB           \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.03 MiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.26 MiB/5.13 MiB           \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.22 MiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.40 MiB/5.13 MiB           \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.33 MiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.57 MiB/5.13 MiB           \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.52 MiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.74 MiB/5.13 MiB           \u001b[2A\n",
      "\u001b[2mtorchvision         \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 1.75 MiB/1.77 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.88 MiB/5.13 MiB           \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.96 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.22 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.64 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)2m------------\u001b[0m\u001b[0m 2.98 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-\u001b[2m---------\u001b[0m\u001b[0m 3.45 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---\u001b[2m-------\u001b[0m\u001b[0m 3.88 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)------\u001b[2m----\u001b[0m\u001b[0m 4.34 MiB/5.13 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 1.13s\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m11 packages\u001b[0m \u001b[2min 670ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing pytorch\n",
    "!uv add torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e772789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m30 packages\u001b[0m \u001b[2min 464ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[1A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 64.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 80.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/36.12 MiB           \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 80.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 16.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 96.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 16.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 96.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 32.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 112.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 32.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 112.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 48.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 128.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 48.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 144.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 48.00 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 144.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 60.82 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 144.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 76.82 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 160.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 76.82 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 160.00 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 92.82 KiB/36.12 MiB         \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 399.89 KiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 444.82 KiB/36.12 MiB        \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 1.05 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 924.82 KiB/36.12 MiB        \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.62 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.47 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.94 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 1.75 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 2.22 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 2.12 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 2.55 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 2.39 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 2.88 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 2.68 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 3.14 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 3.01 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 3.47 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 3.31 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 3.77 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 3.61 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 4.08 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 3.92 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 4.39 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 4.20 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 4.72 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 4.50 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 4.98 MiB/5.10 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 4.83 MiB/36.12 MiB          \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 4.98 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 5.33 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 5.94 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 6.56 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 7.15 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 7.78 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 7.89 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 7.90 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 9.61 MiB/36.12 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 10.25 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 10.83 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 11.45 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 12.06 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 12.67 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 13.29 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 13.90 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 14.52 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 15.11 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 15.73 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 16.34 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 16.97 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 17.58 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 18.20 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 18.79 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)m-------------\u001b[0m\u001b[0m 19.41 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)m-------------\u001b[0m\u001b[0m 20.02 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)2m------------\u001b[0m\u001b[0m 20.64 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)2m------------\u001b[0m\u001b[0m 21.25 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)[2m-----------\u001b[0m\u001b[0m 21.84 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)[2m-----------\u001b[0m\u001b[0m 22.47 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)\u001b[2m----------\u001b[0m\u001b[0m 23.06 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)\u001b[2m----------\u001b[0m\u001b[0m 23.69 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-\u001b[2m---------\u001b[0m\u001b[0m 24.33 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-\u001b[2m---------\u001b[0m\u001b[0m 24.92 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--\u001b[2m--------\u001b[0m\u001b[0m 25.53 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--\u001b[2m--------\u001b[0m\u001b[0m 26.14 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---\u001b[2m-------\u001b[0m\u001b[0m 26.76 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---\u001b[2m-------\u001b[0m\u001b[0m 27.36 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[2m------\u001b[0m\u001b[0m 27.98 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[2m------\u001b[0m\u001b[0m 28.59 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-----\u001b[2m-----\u001b[0m\u001b[0m 29.20 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-----\u001b[2m-----\u001b[0m\u001b[0m 29.83 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)------\u001b[2m----\u001b[0m\u001b[0m 30.44 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)------\u001b[2m----\u001b[0m\u001b[0m 31.03 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-------\u001b[2m---\u001b[0m\u001b[0m 31.66 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-------\u001b[2m---\u001b[0m\u001b[0m 32.28 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------\u001b[2m--\u001b[0m\u001b[0m 32.89 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------\u001b[2m--\u001b[0m\u001b[0m 33.48 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------\u001b[2m-\u001b[0m\u001b[0m 34.11 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------\u001b[2m-\u001b[0m\u001b[0m 34.70 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----------\u001b[2m\u001b[0m\u001b[0m 35.31 MiB/36.12 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 3.36s\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 96ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 17ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26d34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing std dependencies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2710cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pytorch dependencies\n",
    "import torch\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "066d1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65714d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'os.makedirs(POS_PATH)\\nos.makedirs(NEG_PATH)\\nos.makedirs(ANC_PATH)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating folders\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')\n",
    "'''os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06941f55",
   "metadata": {},
   "source": [
    "moving lfw images to negative folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b1ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir('lfw_funneled'):\n",
    "    if os.path.isdir(os.path.join('lfw_funneled',directory,file)):\n",
    "            for file in os.listdir('lfw_funneled'+'/'+directory):\n",
    "        \n",
    "                \n",
    "                EX_PATH = os.path.join('lfw_funneled',directory,file)\n",
    "                NEW_PATH = os.path.join(NEG_PATH,file)\n",
    "                os.replace(EX_PATH,NEW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5114968",
   "metadata": {},
   "source": [
    "collecting anchor and positive images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795cbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # cutting frame to 250 by 250px\n",
    "    frame = frame[0:250, 0:250 ,:]\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    #collecting anchors \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        pass\n",
    "\n",
    "    #collecting positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "      pass\n",
    "\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image (OpenCV loads as BGR)\n",
    "img = cv2.imread('data/anchor/447a4b68-acb7-11f0-b160-221fedd10dee.jpg')\n",
    "\n",
    "# Convert BGR → RGB for correct display in matplotlib\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Show in notebook\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8db73",
   "metadata": {},
   "source": [
    "Getting image directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abca2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "\n",
    "\n",
    "# List all matching files and take the first 300\n",
    "anchor_files = glob.glob(ANC_PATH + '/*.jpg')[:300]\n",
    "positive_files = glob.glob(POS_PATH + '/*.jpg')[:300]\n",
    "negative_files = glob.glob(NEG_PATH + '/*.jpg')[:300]\n",
    "\n",
    "#creating custom dataset\n",
    "class FilePathDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.file_list[idx]\n",
    "\n",
    "\n",
    "anchor = FilePathDataset(anchor_files)\n",
    "postive = FilePathDataset(positive_files)\n",
    "negative = FilePathDataset(negative_files)\n",
    "\n",
    "#creating dataloader\n",
    "dir_test = DataLoader(anchor, batch_size=1)\n",
    "\n",
    "dir_test_iter = iter(dir_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e57388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postive.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2674b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/anchor/447a4b68-acb7-11f0-b160-221fedd10dee.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(next(dir_test_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d30703",
   "metadata": {},
   "source": [
    "Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae03fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img = preprocess(\"data/anchor/61434828-a2b0-11f0-b077-221fedd10dee.jpg\")\\nplt.imshow(img.permute(1,2,0))\\nplt.show()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.io import decode_image,read_file\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "'''def preprocess(img_path):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = transforms.Resize((100, 100))(image)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    return image'''\n",
    "\n",
    "def preprocess(img_path):\n",
    "    img_bytes = read_file(img_path)\n",
    "    image = decode_image(img_bytes)\n",
    "    image = torchvision.transforms.Resize((100,100))(image)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "#example \n",
    "'''img = preprocess(\"data/anchor/61434828-a2b0-11f0-b077-221fedd10dee.jpg\")\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec5a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img,validation_img,label):\n",
    "    input_img = preprocess(input_img)\n",
    "    validation_img = preprocess(validation_img)\n",
    "    return (input_img,validation_img,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a568c73",
   "metadata": {},
   "source": [
    "Creating labelled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c84b28a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6706, 0.6706, 0.6706,  ..., 0.4118, 0.4078, 0.4078],\n",
       "          [0.6745, 0.6745, 0.6745,  ..., 0.4078, 0.4078, 0.4157],\n",
       "          [0.6784, 0.6784, 0.6745,  ..., 0.4118, 0.4157, 0.4235],\n",
       "          ...,\n",
       "          [0.2431, 0.2000, 0.2000,  ..., 0.3333, 0.3529, 0.3765],\n",
       "          [0.1725, 0.2000, 0.2471,  ..., 0.4667, 0.3843, 0.3608],\n",
       "          [0.1922, 0.2745, 0.2863,  ..., 0.5922, 0.5765, 0.5020]],\n",
       " \n",
       "         [[0.5647, 0.5647, 0.5647,  ..., 0.3529, 0.3569, 0.3490],\n",
       "          [0.5686, 0.5686, 0.5686,  ..., 0.3529, 0.3569, 0.3569],\n",
       "          [0.5725, 0.5725, 0.5686,  ..., 0.3529, 0.3608, 0.3569],\n",
       "          ...,\n",
       "          [0.2392, 0.1922, 0.2000,  ..., 0.4118, 0.4118, 0.4275],\n",
       "          [0.1686, 0.1961, 0.2431,  ..., 0.5686, 0.4863, 0.4588],\n",
       "          [0.1922, 0.2745, 0.2824,  ..., 0.6784, 0.6745, 0.6039]],\n",
       " \n",
       "         [[0.4980, 0.4980, 0.4980,  ..., 0.2980, 0.2941, 0.2902],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.3020, 0.2980, 0.2980],\n",
       "          [0.5059, 0.5059, 0.5020,  ..., 0.3020, 0.3020, 0.3020],\n",
       "          ...,\n",
       "          [0.2549, 0.2078, 0.2118,  ..., 0.4824, 0.4784, 0.4902],\n",
       "          [0.1922, 0.2157, 0.2627,  ..., 0.6431, 0.5686, 0.5490],\n",
       "          [0.2118, 0.2941, 0.3020,  ..., 0.7412, 0.7451, 0.6824]]]),\n",
       " tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0039, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0039, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "\n",
    "# Example paths\n",
    "anchor_files = glob.glob(ANC_PATH + '/*.jpg')[:57]\n",
    "positive_files = glob.glob(POS_PATH + '/*.jpg')[:57]\n",
    "negative_files = glob.glob(NEG_PATH + '/*.jpg')[:57]\n",
    "\n",
    "\n",
    "# Dataset that returns (anchor_path, other_path, label)\n",
    "class PairedFilePathDataset(Dataset):\n",
    "    def __init__(self, anchor_files, other_files, label,transform = None):\n",
    "        assert len(anchor_files) == len(other_files), \"Anchor and other files must match in length\"\n",
    "        self.anchor_files = anchor_files\n",
    "        self.other_files = other_files\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.cache = {}  # in-memory caching\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            return self.cache[idx]\n",
    "        anchor_path = self.anchor_files[idx]\n",
    "        other_path = self.other_files[idx]\n",
    "        label_tensor = torch.tensor(self.label, dtype=torch.float32)\n",
    "         # Apply preprocessing function here\n",
    "        if self.transform:\n",
    "            anchor_path, other_path,label_tensor = self.transform(anchor_path, other_path,label_tensor)\n",
    "        sample = (anchor_path, other_path, label_tensor)\n",
    "        self.cache[idx] = sample  # cache it in memory\n",
    "        return sample\n",
    "\n",
    "\n",
    "# Create positive and negative datasets\n",
    "positive_dataset = PairedFilePathDataset(anchor_files, positive_files, label=1,transform=preprocess_twin)\n",
    "negative_dataset = PairedFilePathDataset(anchor_files, negative_files, label=0,transform=preprocess_twin)\n",
    "\n",
    "# Combine datasets manually (no ConcatDataset nesting)\n",
    "full_dataset = positive_dataset + negative_dataset  # works because __getitem__ returns tuples\n",
    "\n",
    "\n",
    "# Custom collate function to return tuple directly\n",
    "def single_collate_fn(batch):\n",
    "    # batch is a list of 1 item if batch_size=1\n",
    "    anchor, other, label = batch[0]\n",
    "    return anchor, other, label\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "paired_dataloader = DataLoader(\n",
    "    full_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=single_collate_fn\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "example = next(iter(paired_dataloader))\n",
    "example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6629090",
   "metadata": {},
   "source": [
    "Building train and test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a15e181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a204cd6",
   "metadata": {},
   "source": [
    "Building a data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72e238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "total_len = len(full_dataset)\n",
    "train_len = int(0.7 * total_len)\n",
    "test_len = total_len - train_len\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True      # shuffles the dataset every epoch\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18419714",
   "metadata": {},
   "source": [
    "Building an embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0fb455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(10, 10), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 10)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 7)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 4096)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.fc1(x))  \n",
    "        return x\n",
    "\n",
    "model = Embedding()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e627db3",
   "metadata": {},
   "source": [
    "Creating siamese L1 distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3093fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(nn.Module):\n",
    "    def __init__(self)->None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,input_embedding,validation_embedding):\n",
    "        return torch.abs(input_embedding - validation_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9442a2",
   "metadata": {},
   "source": [
    "Creating siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fafa6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNeuralNetwork, self).__init__()\n",
    "        self.embedding = Embedding()\n",
    "        self.L1Dist = L1Dist()\n",
    "        self.fc1 = nn.Linear(4096,1)\n",
    "\n",
    "    def forward(self,input_img,validation_img):\n",
    "        input_embedding = self.embedding(input_img)\n",
    "        validation_embedding = self.embedding(validation_img)\n",
    "\n",
    "        l1_distance = self.L1Dist(input_embedding,validation_embedding)\n",
    "        output = torch.sigmoid(self.fc1(l1_distance))\n",
    "        return output\n",
    "\n",
    "model = SiameseNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d9494",
   "metadata": {},
   "source": [
    "Creating Train step model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4506a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30846a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef524e2d",
   "metadata": {},
   "source": [
    "setting up checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6abffcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac28e1",
   "metadata": {},
   "source": [
    "setting up loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96ceac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c208f7fe",
   "metadata": {},
   "source": [
    "Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d1b7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(batch):\n",
    "    model.train()\n",
    "    anchor_img,validation_img,label = batch\n",
    "    label = label.unsqueeze(1)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(anchor_img,validation_img)\n",
    "    loss = lossfn(output,label)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93b375",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b593dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,epochs):\n",
    "    for epoch in range(1,epochs+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, epochs))\n",
    "        for batch in data:\n",
    "            loss = train_one_epoch(batch)\n",
    "            print(f\"Epoch {epoch+1} Loss: {loss}\")\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(model.state_dict(), f\"{checkpoint_prefix}/siamese_epoch_{epoch}.pth\")\n",
    "            print(f\"Model saved at epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad27c40",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86a650a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 2 Loss: 0.6941414475440979\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 2 Loss: 0.6897565126419067\n",
      "tensor(0.6810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 2 Loss: 0.6810295581817627\n",
      "tensor(0.6646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 2 Loss: 0.6645702123641968\n",
      "tensor(0.6809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 2 Loss: 0.6809360980987549\n",
      "\n",
      " Epoch 2/50\n",
      "tensor(0.6460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 3 Loss: 0.646033763885498\n",
      "tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 3 Loss: 0.5599795579910278\n",
      "tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 3 Loss: 0.5812582969665527\n",
      "tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 3 Loss: 0.4297126531600952\n",
      "tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 3 Loss: 0.5201035141944885\n",
      "\n",
      " Epoch 3/50\n",
      "tensor(0.3565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 4 Loss: 0.3565317988395691\n",
      "tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 4 Loss: 0.4575175940990448\n",
      "tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 4 Loss: 0.6075496077537537\n",
      "tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 4 Loss: 0.552769660949707\n",
      "tensor(0.4783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 4 Loss: 0.4782605469226837\n",
      "\n",
      " Epoch 4/50\n",
      "tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 5 Loss: 0.4292607307434082\n",
      "tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 5 Loss: 0.5119721293449402\n",
      "tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 5 Loss: 0.5201240181922913\n",
      "tensor(0.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 5 Loss: 0.4303756058216095\n",
      "tensor(0.3345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 5 Loss: 0.3344675302505493\n",
      "\n",
      " Epoch 5/50\n",
      "tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 6 Loss: 0.4947727620601654\n",
      "tensor(0.3330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 6 Loss: 0.33296501636505127\n",
      "tensor(0.4072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 6 Loss: 0.4072052240371704\n",
      "tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 6 Loss: 0.4387923777103424\n",
      "tensor(0.2888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 6 Loss: 0.28883570432662964\n",
      "\n",
      " Epoch 6/50\n",
      "tensor(0.3711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 7 Loss: 0.37111154198646545\n",
      "tensor(0.2715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 7 Loss: 0.27154794335365295\n",
      "tensor(0.2952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 7 Loss: 0.29516473412513733\n",
      "tensor(0.3845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 7 Loss: 0.3844957947731018\n",
      "tensor(0.3809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 7 Loss: 0.3809289336204529\n",
      "\n",
      " Epoch 7/50\n",
      "tensor(0.2718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 8 Loss: 0.2717604637145996\n",
      "tensor(0.2770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 8 Loss: 0.27697238326072693\n",
      "tensor(0.2910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 8 Loss: 0.2909512221813202\n",
      "tensor(0.2754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 8 Loss: 0.2754039764404297\n",
      "tensor(0.2439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 8 Loss: 0.2438930869102478\n",
      "\n",
      " Epoch 8/50\n",
      "tensor(0.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 9 Loss: 0.2098860740661621\n",
      "tensor(0.1966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 9 Loss: 0.19664259254932404\n",
      "tensor(0.1671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 9 Loss: 0.16707876324653625\n",
      "tensor(0.1373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 9 Loss: 0.13731077313423157\n",
      "tensor(0.2484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 9 Loss: 0.24835847318172455\n",
      "\n",
      " Epoch 9/50\n",
      "tensor(0.1216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 10 Loss: 0.12158074975013733\n",
      "tensor(0.1522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 10 Loss: 0.15223807096481323\n",
      "tensor(0.1022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 10 Loss: 0.10221771895885468\n",
      "tensor(0.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 10 Loss: 0.13502022624015808\n",
      "tensor(0.1378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 10 Loss: 0.13783057034015656\n",
      "\n",
      " Epoch 10/50\n",
      "tensor(0.1051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 11 Loss: 0.10506924986839294\n",
      "tensor(0.0377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 11 Loss: 0.037743210792541504\n",
      "tensor(0.1059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 11 Loss: 0.10585945844650269\n",
      "tensor(0.0527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 11 Loss: 0.052684154361486435\n",
      "tensor(0.0705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 11 Loss: 0.07051754742860794\n",
      "Model saved at epoch 10\n",
      "\n",
      " Epoch 11/50\n",
      "tensor(0.0644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 12 Loss: 0.06441405415534973\n",
      "tensor(0.0362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 12 Loss: 0.03622470051050186\n",
      "tensor(0.3912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 12 Loss: 0.391232967376709\n",
      "tensor(0.0110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 12 Loss: 0.011016065254807472\n",
      "tensor(0.1271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 12 Loss: 0.1271396279335022\n",
      "\n",
      " Epoch 12/50\n",
      "tensor(0.0682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 13 Loss: 0.0682198777794838\n",
      "tensor(0.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 13 Loss: 0.41115254163742065\n",
      "tensor(0.1522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 13 Loss: 0.15216770768165588\n",
      "tensor(0.1365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 13 Loss: 0.13652688264846802\n",
      "tensor(0.0648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 13 Loss: 0.06480609625577927\n",
      "\n",
      " Epoch 13/50\n",
      "tensor(0.0857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 14 Loss: 0.08574925363063812\n",
      "tensor(0.0703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 14 Loss: 0.07032094895839691\n",
      "tensor(0.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 14 Loss: 0.12362967431545258\n",
      "tensor(0.0556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 14 Loss: 0.055624593049287796\n",
      "tensor(0.0857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 14 Loss: 0.08574368059635162\n",
      "\n",
      " Epoch 14/50\n",
      "tensor(0.1105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 15 Loss: 0.11051446199417114\n",
      "tensor(0.0762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 15 Loss: 0.07617685943841934\n",
      "tensor(0.0908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 15 Loss: 0.09075617790222168\n",
      "tensor(0.0968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 15 Loss: 0.09677467495203018\n",
      "tensor(0.0955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 15 Loss: 0.09552422910928726\n",
      "\n",
      " Epoch 15/50\n",
      "tensor(0.1134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 16 Loss: 0.11339900642633438\n",
      "tensor(0.0388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 16 Loss: 0.03881296142935753\n",
      "tensor(0.0401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 16 Loss: 0.040118344128131866\n",
      "tensor(0.0610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 16 Loss: 0.06100441887974739\n",
      "tensor(0.0299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 16 Loss: 0.029871009290218353\n",
      "\n",
      " Epoch 16/50\n",
      "tensor(0.0471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 17 Loss: 0.047141946852207184\n",
      "tensor(0.0370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 17 Loss: 0.03704170137643814\n",
      "tensor(0.0346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 17 Loss: 0.03459157794713974\n",
      "tensor(0.0744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 17 Loss: 0.07435200363397598\n",
      "tensor(0.0164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 17 Loss: 0.016429638490080833\n",
      "\n",
      " Epoch 17/50\n",
      "tensor(0.0459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 18 Loss: 0.045891083776950836\n",
      "tensor(0.0640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 18 Loss: 0.06396351009607315\n",
      "tensor(0.0105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 18 Loss: 0.01047844160348177\n",
      "tensor(0.0194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 18 Loss: 0.019365347921848297\n",
      "tensor(0.0110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 18 Loss: 0.011037096381187439\n",
      "\n",
      " Epoch 18/50\n",
      "tensor(0.0176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 19 Loss: 0.017558027058839798\n",
      "tensor(0.0211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 19 Loss: 0.021114006638526917\n",
      "tensor(0.0211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 19 Loss: 0.02107331156730652\n",
      "tensor(0.0102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 19 Loss: 0.010194231756031513\n",
      "tensor(0.0113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 19 Loss: 0.011343627236783504\n",
      "\n",
      " Epoch 19/50\n",
      "tensor(0.0064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 20 Loss: 0.006415678188204765\n",
      "tensor(0.0217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 20 Loss: 0.021689098328351974\n",
      "tensor(0.0300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 20 Loss: 0.029982056468725204\n",
      "tensor(0.0054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 20 Loss: 0.005449353251606226\n",
      "tensor(0.0066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 20 Loss: 0.006625516805797815\n",
      "\n",
      " Epoch 20/50\n",
      "tensor(0.0182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 21 Loss: 0.01823890209197998\n",
      "tensor(0.0014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 21 Loss: 0.0014316444285213947\n",
      "tensor(0.0076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 21 Loss: 0.007587113883346319\n",
      "tensor(0.0072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 21 Loss: 0.007232220843434334\n",
      "tensor(0.0129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 21 Loss: 0.0129090566188097\n",
      "Model saved at epoch 20\n",
      "\n",
      " Epoch 21/50\n",
      "tensor(0.0075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 22 Loss: 0.007484729867428541\n",
      "tensor(0.0088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 22 Loss: 0.008841666392982006\n",
      "tensor(0.0049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 22 Loss: 0.004917178303003311\n",
      "tensor(0.0145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 22 Loss: 0.01446764636784792\n",
      "tensor(0.0041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 22 Loss: 0.004143633879721165\n",
      "\n",
      " Epoch 22/50\n",
      "tensor(0.0121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 23 Loss: 0.012135136872529984\n",
      "tensor(0.0030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 23 Loss: 0.0030091109219938517\n",
      "tensor(0.0033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 23 Loss: 0.003274169284850359\n",
      "tensor(0.0100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 23 Loss: 0.009986216202378273\n",
      "tensor(0.0015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 23 Loss: 0.0015004347078502178\n",
      "\n",
      " Epoch 23/50\n",
      "tensor(0.0071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 24 Loss: 0.007116206921637058\n",
      "tensor(0.0033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 24 Loss: 0.0033195577561855316\n",
      "tensor(0.0060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 24 Loss: 0.006018945947289467\n",
      "tensor(0.0029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 24 Loss: 0.0028841481544077396\n",
      "tensor(0.0030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 24 Loss: 0.0030443540308624506\n",
      "\n",
      " Epoch 24/50\n",
      "tensor(0.0039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 25 Loss: 0.003866213606670499\n",
      "tensor(0.0090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 25 Loss: 0.008962897583842278\n",
      "tensor(0.0023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 25 Loss: 0.0022887415252625942\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 25 Loss: 0.001086641103029251\n",
      "tensor(0.0028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 25 Loss: 0.0028408688958734274\n",
      "\n",
      " Epoch 25/50\n",
      "tensor(0.0017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 26 Loss: 0.0016961375949904323\n",
      "tensor(0.0077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 26 Loss: 0.007720420137047768\n",
      "tensor(0.0028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 26 Loss: 0.00280994875356555\n",
      "tensor(0.0021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 26 Loss: 0.0020793979056179523\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 26 Loss: 0.0010526436381042004\n",
      "\n",
      " Epoch 26/50\n",
      "tensor(0.0037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 27 Loss: 0.0037394941318780184\n",
      "tensor(0.0018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 27 Loss: 0.0018399306572973728\n",
      "tensor(0.0023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 27 Loss: 0.002283746376633644\n",
      "tensor(0.0046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 27 Loss: 0.004558461718261242\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 27 Loss: 0.0007649707840755582\n",
      "\n",
      " Epoch 27/50\n",
      "tensor(0.0025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 28 Loss: 0.002542604459449649\n",
      "tensor(0.0020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 28 Loss: 0.002025286201387644\n",
      "tensor(0.0034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 28 Loss: 0.0033605294302105904\n",
      "tensor(0.0029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 28 Loss: 0.0029291429091244936\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 28 Loss: 0.0009555119322612882\n",
      "\n",
      " Epoch 28/50\n",
      "tensor(0.0013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 29 Loss: 0.0013199775712564588\n",
      "tensor(0.0041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 29 Loss: 0.004061412997543812\n",
      "tensor(0.0024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 29 Loss: 0.0024047631304711103\n",
      "tensor(0.0020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 29 Loss: 0.0020020008087158203\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 29 Loss: 0.00047008981346152723\n",
      "\n",
      " Epoch 29/50\n",
      "tensor(0.0023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 30 Loss: 0.0023421018850058317\n",
      "tensor(0.0022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 30 Loss: 0.0021917091216892004\n",
      "tensor(0.0018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 30 Loss: 0.001839806092903018\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 30 Loss: 0.0006459535798057914\n",
      "tensor(0.0021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 30 Loss: 0.0021317051723599434\n",
      "\n",
      " Epoch 30/50\n",
      "tensor(0.0022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 31 Loss: 0.0021758130751550198\n",
      "tensor(0.0012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 31 Loss: 0.0011718675959855318\n",
      "tensor(0.0015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 31 Loss: 0.0015005103778094053\n",
      "tensor(0.0033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 31 Loss: 0.0032542531844228506\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 31 Loss: 0.000283181230770424\n",
      "Model saved at epoch 30\n",
      "\n",
      " Epoch 31/50\n",
      "tensor(0.0013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 32 Loss: 0.001298784976825118\n",
      "tensor(0.0017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 32 Loss: 0.001661614514887333\n",
      "tensor(0.0031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 32 Loss: 0.0030809531453996897\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 32 Loss: 0.0007757684797979891\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 32 Loss: 0.0007622189586982131\n",
      "\n",
      " Epoch 32/50\n",
      "tensor(0.0012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 33 Loss: 0.0012120086466893554\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 33 Loss: 0.0011081951670348644\n",
      "tensor(0.0027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 33 Loss: 0.0026812036521732807\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 33 Loss: 0.0003909527731593698\n",
      "tensor(0.0016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 33 Loss: 0.0015656298492103815\n",
      "\n",
      " Epoch 33/50\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 34 Loss: 0.0011052493937313557\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 34 Loss: 0.0008967330795712769\n",
      "tensor(0.0014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 34 Loss: 0.0013821228640154004\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 34 Loss: 0.0010240876581519842\n",
      "tensor(0.0021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 34 Loss: 0.002143333200365305\n",
      "\n",
      " Epoch 34/50\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 35 Loss: 0.0010296674445271492\n",
      "tensor(0.0015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 35 Loss: 0.0015271921874955297\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 35 Loss: 0.0008713366696611047\n",
      "tensor(0.0021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 35 Loss: 0.002130206674337387\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 35 Loss: 0.0003853690577670932\n",
      "\n",
      " Epoch 35/50\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 36 Loss: 0.0005037357332184911\n",
      "tensor(0.0029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 36 Loss: 0.0029143239371478558\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 36 Loss: 0.00043395854299888015\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 36 Loss: 0.0010919885244220495\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 36 Loss: 0.0006178158218972385\n",
      "\n",
      " Epoch 36/50\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 37 Loss: 0.0008925572037696838\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 37 Loss: 0.0009587029344402254\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 37 Loss: 0.0004033453587908298\n",
      "tensor(0.0018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 37 Loss: 0.0017820695647969842\n",
      "tensor(0.0012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 37 Loss: 0.0011582843726500869\n",
      "\n",
      " Epoch 37/50\n",
      "tensor(0.0021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 38 Loss: 0.002084496198222041\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 38 Loss: 0.0004152664332650602\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 38 Loss: 0.0007500539068132639\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 38 Loss: 0.0002692513517104089\n",
      "tensor(0.0014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 38 Loss: 0.0014103826833888888\n",
      "\n",
      " Epoch 38/50\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 39 Loss: 0.00030137793510220945\n",
      "tensor(0.0017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 39 Loss: 0.001745146932080388\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 39 Loss: 0.0005884108832105994\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 39 Loss: 0.00048361907829530537\n",
      "tensor(0.0014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 39 Loss: 0.0014464660780504346\n",
      "\n",
      " Epoch 39/50\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 40 Loss: 0.00023871877056080848\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 40 Loss: 0.0004906313843093812\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 40 Loss: 0.0009513830882497132\n",
      "tensor(0.0022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 40 Loss: 0.0022398880682885647\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 40 Loss: 0.0003496087738312781\n",
      "\n",
      " Epoch 40/50\n",
      "tensor(0.0007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 41 Loss: 0.0007042284123599529\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 41 Loss: 0.0003954495768994093\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 41 Loss: 0.0006372663192451\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 41 Loss: 0.0010041496716439724\n",
      "tensor(0.0014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 41 Loss: 0.0013667299645021558\n",
      "Model saved at epoch 40\n",
      "\n",
      " Epoch 41/50\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 42 Loss: 0.0005449668387882411\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 42 Loss: 0.0004717919509857893\n",
      "tensor(0.0012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 42 Loss: 0.0011615807889029384\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 42 Loss: 0.000585123139899224\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 42 Loss: 0.0010890478733927011\n",
      "\n",
      " Epoch 42/50\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 43 Loss: 0.0006036293925717473\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 43 Loss: 0.00050552241737023\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 43 Loss: 0.0006497765425592661\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 43 Loss: 0.000974737573415041\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 43 Loss: 0.0009371500345878303\n",
      "\n",
      " Epoch 43/50\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 44 Loss: 0.00024125431082211435\n",
      "tensor(0.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 44 Loss: 0.0010967872804030776\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 44 Loss: 0.0007592992624267936\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 44 Loss: 0.00047960347728803754\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 44 Loss: 0.0008654355769976974\n",
      "\n",
      " Epoch 44/50\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 45 Loss: 0.0005463476409204304\n",
      "tensor(0.0007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 45 Loss: 0.0007133585168048739\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 45 Loss: 0.0008101126877591014\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 45 Loss: 0.000910319562535733\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 45 Loss: 0.0002727291139308363\n",
      "\n",
      " Epoch 45/50\n",
      "tensor(0.0007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 46 Loss: 0.0007321385201066732\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 46 Loss: 0.0005817491328343749\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 46 Loss: 0.0006205610116012394\n",
      "tensor(0.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 46 Loss: 0.0008179783471859992\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 46 Loss: 0.000388684420613572\n",
      "\n",
      " Epoch 46/50\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 47 Loss: 0.0009896857663989067\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 47 Loss: 0.0004810701066162437\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 47 Loss: 0.0005109842750243843\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 47 Loss: 0.00034065640647895634\n",
      "tensor(0.0007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 47 Loss: 0.0007270783535204828\n",
      "\n",
      " Epoch 47/50\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 48 Loss: 0.000924767809920013\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 48 Loss: 0.00018543309124652296\n",
      "tensor(0.0007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 48 Loss: 0.0007010270492173731\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 48 Loss: 0.0002374702162342146\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 48 Loss: 0.0008501326665282249\n",
      "\n",
      " Epoch 48/50\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 49 Loss: 0.00041129038436338305\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 49 Loss: 0.00024927101912908256\n",
      "tensor(0.0009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 49 Loss: 0.0009453397942706943\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 49 Loss: 0.0004932486917823553\n",
      "tensor(0.0006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 49 Loss: 0.0005825607222504914\n",
      "\n",
      " Epoch 49/50\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 50 Loss: 0.0002352226001676172\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 50 Loss: 0.00040415197145193815\n",
      "tensor(0.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 50 Loss: 0.0002669446403160691\n",
      "tensor(0.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 50 Loss: 0.0004827125230804086\n",
      "tensor(0.0012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 50 Loss: 0.0012087839422747493\n",
      "\n",
      " Epoch 50/50\n",
      "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 51 Loss: 0.0001979513472178951\n",
      "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 51 Loss: 0.0003747790469788015\n",
      "tensor(0.0001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 51 Loss: 0.00013778744323644787\n",
      "tensor(0.0007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 51 Loss: 0.0007188307354226708\n",
      "tensor(0.0010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 51 Loss: 0.0010139322839677334\n",
      "Model saved at epoch 50\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train(train_loader,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c33b3a",
   "metadata": {},
   "source": [
    "Evaluating model and making visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2f6c6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5023],\n",
       "        [0.5023],\n",
       "        [0.5024],\n",
       "        [0.5023],\n",
       "        [0.5023],\n",
       "        [0.5024],\n",
       "        [0.5024],\n",
       "        [0.5023],\n",
       "        [0.5024],\n",
       "        [0.5023],\n",
       "        [0.5023],\n",
       "        [0.5023],\n",
       "        [0.5024],\n",
       "        [0.5022],\n",
       "        [0.5025],\n",
       "        [0.5023]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing metrics\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "test_input, test_val, test_label = batch_1\n",
    "y_pred = model(test_input,test_val)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "064d9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.tensor([1 if prediction > 0.5 else 0 for prediction in y_pred])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa2547e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9151f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 1.0\n",
      "accuracy: 1.0\n",
      "recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "#calculating metrics\n",
    "p = Precision(task=\"binary\")\n",
    "a = Accuracy(task=\"binary\")\n",
    "r = Recall(task=\"binary\")\n",
    "precision = p(y_pred,test_label)\n",
    "accuracy = a(y_pred,test_label)\n",
    "recall = r(y_pred,test_label)\n",
    "print(\"precision:\",precision.item())\n",
    "print(\"accuracy:\",accuracy.item())\n",
    "print(\"recall:\",recall.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c20b7",
   "metadata": {},
   "source": [
    "Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[2].permute(1,2,0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[2].permute(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a77128",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "564083f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'siamese_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9449cac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNeuralNetwork(\n",
       "  (embedding): Embedding(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(10, 10), stride=(1, 1))\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "  )\n",
       "  (L1Dist): L1Dist()\n",
       "  (fc1): Linear(in_features=4096, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reloading the model \n",
    "model = torch.load('siamese_model.pth',weights_only=False)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b28b4340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00],\n",
       "        [4.7314e-04],\n",
       "        [1.2407e-05],\n",
       "        [9.9770e-01],\n",
       "        [6.6275e-07],\n",
       "        [2.9213e-04],\n",
       "        [4.5840e-06],\n",
       "        [9.8801e-01],\n",
       "        [9.9987e-01],\n",
       "        [5.6815e-05],\n",
       "        [9.9977e-01],\n",
       "        [9.9833e-01],\n",
       "        [8.0892e-06],\n",
       "        [9.9998e-01],\n",
       "        [3.5733e-07],\n",
       "        [1.0000e+00]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting \n",
    "prediction = model(test_input,test_val)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ac9f4",
   "metadata": {},
   "source": [
    "Real time test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d499fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model,detection_threshold,verification_threshold):\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data','verification_images')):\n",
    "        if(image.endswith('.jpg')==False):\n",
    "            continue\n",
    "        input_img = preprocess(os.path.join('application_data','input_image','input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data','verification_images',image))\n",
    "        \n",
    "        input_img = input_img.unsqueeze(0)\n",
    "        validation_img = validation_img.unsqueeze(0)\n",
    "        \n",
    "        output = model(input_img,validation_img)\n",
    "        results.append(output.item())\n",
    "\n",
    "        #detection threshold: tells us is above which value we should consider it to be a positive match\n",
    "        #verification threshold: tells us what percentage of verification images should match to consider it verified\n",
    "        detection = np.sum(np.array(results) > detection_threshold)\n",
    "        verification = detection / len(os.listdir(os.path.join('application_data','verification_images')))\n",
    "        verified = verification > verification_threshold\n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified: True, results: [0.8468645215034485, 0.008444461040198803, 0.824988067150116, 0.0011397842317819595, 0.008139001205563545, 0.8528907895088196, 0.007038509007543325, 0.9904754757881165, 0.0006823272560723126, 0.0022322151344269514, 0.008792937733232975, 0.7709122896194458, 0.8586593270301819, 0.8890367746353149, 0.49415865540504456, 0.8322484493255615, 0.9315831065177917, 0.0007346792845055461, 0.001885408302769065, 0.9753064513206482, 0.006021004170179367, 0.000743978947866708, 0.011461793445050716, 0.9525134563446045, 0.9607352614402771, 0.44182583689689636, 0.8229920268058777, 0.8953891396522522, 0.978950560092926, 0.034712791442871094, 0.0005765804089605808, 0.007391834631562233, 0.6802200078964233, 0.8940867781639099, 0.0011372192529961467, 0.005828074179589748, 0.9565826654434204, 0.8991504311561584, 0.8479660153388977, 0.9965894222259521, 0.9445160627365112, 0.9728336930274963, 0.8012357950210571, 0.9980168342590332, 0.0030442841816693544, 0.009657356888055801, 0.9066675901412964, 0.9699052572250366, 0.015586010180413723, 0.006148028187453747]\n",
      "verified: True, results: [0.8320727348327637, 0.008305325172841549, 0.8586764931678772, 0.0010912810685113072, 0.0080040842294693, 0.8385395407676697, 0.006584363989531994, 0.9899857044219971, 0.0006533047999255359, 0.0021441620774567127, 0.00858697947114706, 0.7519095540046692, 0.8450281620025635, 0.9121944904327393, 0.49406760931015015, 0.8646976351737976, 0.9334279894828796, 0.0007084297831170261, 0.0016786674968898296, 0.973706841468811, 0.005897511728107929, 0.0007137562497518957, 0.011017763055860996, 0.9627082943916321, 0.9686075448989868, 0.44091588258743286, 0.8067272901535034, 0.8843033909797668, 0.9827447533607483, 0.031735338270664215, 0.0005587610648944974, 0.0072517297230660915, 0.6827396750450134, 0.8830352425575256, 0.0010925328824669123, 0.005430447403341532, 0.9629568457603455, 0.9196051955223083, 0.8330971598625183, 0.9965198040008545, 0.9561243653297424, 0.9716801643371582, 0.8392332792282104, 0.9980037808418274, 0.0028864708729088306, 0.009497077204287052, 0.913224995136261, 0.9684820771217346, 0.01420207042247057, 0.0060387179255485535]\n",
      "verified: False, results: [0.4241243600845337, 0.023251311853528023, 0.1768263876438141, 0.0018498941790312529, 0.02237558923661709, 0.43390917778015137, 0.008887691423296928, 0.8991961479187012, 0.0013468438992276788, 0.004093334078788757, 0.024001121520996094, 0.3845197260379791, 0.4521982669830322, 0.3894289433956146, 0.7138532996177673, 0.1802336573600769, 0.9093347787857056, 0.0013708141632378101, 0.03446495532989502, 0.8440197110176086, 0.019514795392751694, 0.001511779148131609, 0.024433953687548637, 0.975357711315155, 0.9801653623580933, 0.6446763277053833, 0.4045701324939728, 0.48572126030921936, 0.9070541262626648, 0.016970325261354446, 0.001232507056556642, 0.02313069812953472, 0.8270732760429382, 0.49337124824523926, 0.0023207953199744225, 0.0051642730832099915, 0.9780981540679932, 0.2714979946613312, 0.41760921478271484, 0.9408281445503235, 0.4193750321865082, 0.8746123313903809, 0.17767392098903656, 0.9550673961639404, 0.004357459954917431, 0.02696673944592476, 0.9564526081085205, 0.8689690232276917, 0.007811714895069599, 0.018071966245770454]\n",
      "verified: False, results: [0.5146682262420654, 0.048664163798093796, 0.16742125153541565, 0.0037471505347639322, 0.046886127442121506, 0.5241343379020691, 0.017615005373954773, 0.919236421585083, 0.002762567950412631, 0.008331132121384144, 0.049996014684438705, 0.4965934753417969, 0.5452342629432678, 0.47231343388557434, 0.8411870002746582, 0.16589348018169403, 0.9570261836051941, 0.002799700479954481, 0.06844117492437363, 0.8929239511489868, 0.04257543757557869, 0.003090979065746069, 0.04940618574619293, 0.9919363260269165, 0.9931918978691101, 0.7929797768592834, 0.5017465353012085, 0.5572861433029175, 0.9572882652282715, 0.03079359233379364, 0.0025569640565663576, 0.04999633505940437, 0.9114733338356018, 0.570879340171814, 0.004751234315335751, 0.010125196538865566, 0.991919994354248, 0.2404690831899643, 0.5045484900474548, 0.942844808101654, 0.3850577473640442, 0.9231845736503601, 0.1877637356519699, 0.9485709071159363, 0.00882703997194767, 0.0563974566757679, 0.9813098907470703, 0.919928789138794, 0.01440510619431734, 0.03870527073740959]\n",
      "verified: False, results: [0.6084475517272949, 0.04288908839225769, 0.20812296867370605, 0.003627344034612179, 0.04131334647536278, 0.6178511381149292, 0.017465677112340927, 0.9437009692192078, 0.0025834671687334776, 0.00812013354152441, 0.043905045837163925, 0.562406599521637, 0.634406328201294, 0.4251650273799896, 0.8256508708000183, 0.2121879607439041, 0.9443937540054321, 0.002682297956198454, 0.02896694652736187, 0.9134648442268372, 0.03397328779101372, 0.002973379800096154, 0.0458822064101696, 0.9787566661834717, 0.9835706949234009, 0.7784746289253235, 0.5870499610900879, 0.6694909334182739, 0.9210633039474487, 0.034118328243494034, 0.0023850288707762957, 0.04079147055745125, 0.8999235033988953, 0.6753732562065125, 0.00456668995320797, 0.010388917289674282, 0.9840778112411499, 0.3154654800891876, 0.6027984023094177, 0.9657315611839294, 0.47038283944129944, 0.9287949800491333, 0.2060379534959793, 0.973750114440918, 0.008688963018357754, 0.0492483414709568, 0.9733468890190125, 0.9253893494606018, 0.01585111767053604, 0.0327637605369091]\n",
      "verified: False, results: [0.5294117331504822, 0.0384192168712616, 0.19417721033096313, 0.0031203273683786392, 0.036992017179727554, 0.5392022132873535, 0.014895886182785034, 0.9264761805534363, 0.0022503864020109177, 0.007017112337052822, 0.03941307216882706, 0.4942967891693115, 0.558124303817749, 0.4300660490989685, 0.8093950152397156, 0.19707289338111877, 0.9416271448135376, 0.002319664927199483, 0.03369147330522537, 0.8914023041725159, 0.031135207042098045, 0.0025832548271864653, 0.04041876271367073, 0.9831668734550476, 0.9866366982460022, 0.7570248246192932, 0.5112767219543457, 0.5858346223831177, 0.928104043006897, 0.02771225944161415, 0.00207726564258337, 0.03724617138504982, 0.8907611966133118, 0.5948443412780762, 0.003968413453549147, 0.008726542815566063, 0.985846221446991, 0.29223573207855225, 0.5218468904495239, 0.9544362425804138, 0.4433862566947937, 0.9151914119720459, 0.19782036542892456, 0.964373767375946, 0.007456950843334198, 0.04427622631192207, 0.9731672406196594, 0.9114570617675781, 0.01292529609054327, 0.029576143249869347]\n",
      "verified: False, results: [0.46530696749687195, 0.027442779392004013, 0.3494971990585327, 0.0022568334825336933, 0.02641587145626545, 0.47521719336509705, 0.01072106882929802, 0.9234049916267395, 0.0016021453775465488, 0.005044739227741957, 0.028188304975628853, 0.42836129665374756, 0.4947386085987091, 0.6253377199172974, 0.7581478953361511, 0.35296326875686646, 0.937382698059082, 0.0016752603696659207, 0.017229538410902023, 0.8759283423423767, 0.021847736090421677, 0.0018369342433288693, 0.029066206887364388, 0.9889153838157654, 0.99058598279953, 0.69771409034729, 0.44633644819259644, 0.5241860747337341, 0.9573955535888672, 0.020603133365511894, 0.001495629781857133, 0.02625834383070469, 0.862677276134491, 0.5337076783180237, 0.002824213122949004, 0.006367093417793512, 0.9878501296043396, 0.4773505926132202, 0.4577532112598419, 0.9591687917709351, 0.6371591091156006, 0.9039855599403381, 0.3564330041408539, 0.9700839519500732, 0.005392615217715502, 0.031649235635995865, 0.9703114032745361, 0.8988488912582397, 0.009555102325975895, 0.020933521911501884]\n",
      "verified: False, results: [0.32159289717674255, 0.0192814152687788, 0.3321684002876282, 0.0014906688593328, 0.01855034939944744, 0.330201655626297, 0.0070658959448337555, 0.8703228235244751, 0.0010839682072401047, 0.003339349990710616, 0.019841019064188004, 0.29944872856140137, 0.34910041093826294, 0.6396022439002991, 0.6838375926017761, 0.3329380452632904, 0.9167207479476929, 0.0011104055447503924, 0.020431440323591232, 0.8060073256492615, 0.01608925126492977, 0.0012311835307627916, 0.019956789910793304, 0.9904881119728088, 0.9913821816444397, 0.6097502112388611, 0.30806612968444824, 0.366584450006485, 0.96022629737854, 0.012646187096834183, 0.0010028673568740487, 0.01917974278330803, 0.8127834796905518, 0.37798869609832764, 0.00189483305439353, 0.004081449005752802, 0.9870352149009705, 0.44809845089912415, 0.31344524025917053, 0.930195152759552, 0.6089288592338562, 0.8554287552833557, 0.3492032587528229, 0.9475927948951721, 0.003541914513334632, 0.022369062528014183, 0.9616191983222961, 0.8480398058891296, 0.0058631920255720615, 0.01498161070048809]\n",
      "verified: False, results: [0.2724792957305908, 0.017847292125225067, 0.3381287753582001, 0.0013246842427179217, 0.01717056706547737, 0.2801997661590576, 0.006289216224104166, 0.8415912389755249, 0.0009755614446476102, 0.0029809758998453617, 0.01838461309671402, 0.257568359375, 0.29828953742980957, 0.6758037209510803, 0.6635311841964722, 0.3364999294281006, 0.9113526940345764, 0.0009885610779747367, 0.023714281618595123, 0.7736230492591858, 0.01537217479199171, 0.0011069165775552392, 0.018165767192840576, 0.99224853515625, 0.9926779270172119, 0.5846040844917297, 0.26172950863838196, 0.3092113435268402, 0.9667433500289917, 0.01080312579870224, 0.0009011070942506194, 0.018221568316221237, 0.7976791262626648, 0.32130593061447144, 0.0017022726824507117, 0.003579930169507861, 0.9879137873649597, 0.44662442803382874, 0.2643957734107971, 0.9108283519744873, 0.6085963845252991, 0.8339453339576721, 0.3659699261188507, 0.9302613139152527, 0.003140152432024479, 0.020815741270780563, 0.9599788188934326, 0.8260086178779602, 0.005005505867302418, 0.014044108800590038]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # cutting frame to 250 by 250px\n",
    "    frame = frame[275:275+250, 550:550+250, :]\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    #saving input image\n",
    "    if cv2.waitKey(1) & 0XFF == ord('v'):\n",
    "        input_img_path = os.path.join('application_data','input_image','input_image.jpg')\n",
    "        cv2.imwrite(input_img_path, frame)\n",
    "        results, verified = verify(model,0.5,0.5)\n",
    "        print(f\"verified: {verified}, results: {results}\")\n",
    "\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66320c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SiameseNeuralNet (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
